{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import category_encoders as ce\n",
    "import pickle\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import klib as kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19749\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/mimic_train.csv')\n",
    "df_test = pd.read_csv('data/mimic_test_death.csv')\n",
    "diagnosis = pd.read_csv('data/MIMIC_metadata_diagnose.csv')\n",
    "metadata_df = pd.read_csv('data/MIMIC_diagnoses.csv')\n",
    "\n",
    "print(len(df_train['hadm_id'].unique()))\n",
    "\n",
    "target = 'los'\n",
    "\n",
    "id_cols = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "\n",
    "final_output_df = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_diagnose_dict = dict(zip(diagnosis.ICD9_CODE, diagnosis.SHORT_DIAGNOSE))\n",
    "long_diagnose_dict = dict(zip(diagnosis.ICD9_CODE, diagnosis.LONG_DIAGNOSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LOS features for each ICD9 code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get all codes from the dataset and left join them with the ICD9 codes from the main dataset table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code1', 'code2', 'code3', 'code4', 'code5', 'code6', 'code7', 'code8', 'code9', 'code10', 'code11', 'code12', 'code13', 'code14', 'code15', 'code16', 'code17', 'code18', 'code19', 'code20', 'code21', 'code22', 'code23', 'code24', 'code25', 'code26', 'code27', 'code28', 'code29', 'code30', 'code31', 'code32', 'code33', 'code34', 'code35', 'code36', 'code37', 'code38', 'code39']\n"
     ]
    }
   ],
   "source": [
    "comorbidities = metadata_df.groupby('HADM_ID').agg(\n",
    "    UNIQUE_DIAGNOSIS_COUNT=('ICD9_CODE', 'nunique'),  # Count of unique ICD9 codes\n",
    "    DIAGNOSIS_COUNT=('ICD9_CODE', 'count'),\n",
    "    ICD9_CODE_LIST=('ICD9_CODE', lambda x: list(x.unique()))  # List of unique ICD9 codes\n",
    ").reset_index()\n",
    "\n",
    "df_train = pd.merge(df_train, comorbidities, left_on='hadm_id', right_on='HADM_ID',how='left').drop(columns='HADM_ID')\n",
    "\n",
    "df_test = pd.merge(df_test, comorbidities, left_on='hadm_id', right_on='HADM_ID',how='left').drop(columns='HADM_ID')\n",
    "\n",
    "target_encoder_cols = []\n",
    "\n",
    "for i in range(1, 40):\n",
    "    df_train[f'code{i}'] = df_train['ICD9_CODE_LIST'].apply(lambda x: x[i-1] if len(x) > i-1 else None)\n",
    "    df_test[f'code{i}'] = df_test['ICD9_CODE_LIST'].apply(lambda x: x[i-1] if len(x) > i-1 else None)\n",
    "    target_encoder_cols.append(f'code{i}')\n",
    "\n",
    "\n",
    "metadata_df.columns = ['subject_id', 'hadm_id', 'SEQ_NUM', 'ICD9_CODE']\n",
    "\n",
    "print(target_encoder_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get the LOS for each ICD9 code so we can sum it up later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_merge = df_train[[\"subject_id\", \"hadm_id\", \"LOS\"]]\n",
    "meta_data_merge = pd.merge(metadata_df, X_train_merge, how = \"left\", on = [\"subject_id\", \"hadm_id\"])\n",
    "\n",
    "ICD9_mean = meta_data_merge.groupby('ICD9_CODE').agg({'LOS' : 'mean'}).rename(columns = {'LOS': 'mean'})\n",
    "meta_data_merge = pd.merge(meta_data_merge, ICD9_mean, how = \"left\", on = \"ICD9_CODE\")\n",
    "\n",
    "meta_data_merge_wide = pd.DataFrame(meta_data_merge.pivot_table(index = [\"subject_id\", \"hadm_id\"], columns = \"SEQ_NUM\", values = \"mean\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collapse the data to get the LOS metrics for all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name_covariates = meta_data_merge_wide.columns.tolist()\n",
    "coveriates_of_interest = [col for col in name_covariates if isinstance(col, float) and 1.0 <= col <= 39.0]\n",
    "\n",
    "# Select the columns and calculate the mean, ignoring NaN values with skipna=True\n",
    "meta_data_merge_wide['ICD9_mean'] = meta_data_merge_wide[coveriates_of_interest].mean(axis=1, skipna=True)\n",
    "meta_data_merge_wide['ICD9_max'] = meta_data_merge_wide[coveriates_of_interest].max(axis=1, skipna=True)\n",
    "meta_data_merge_wide['ICD9_sum'] = meta_data_merge_wide[coveriates_of_interest].sum(axis=1, skipna=True)\n",
    "meta_data_merge_wide = meta_data_merge_wide.drop(coveriates_of_interest, axis = 1)\n",
    "\n",
    "df_train = pd.merge(df_train, meta_data_merge_wide, how = \"left\", on = [\"subject_id\", \"hadm_id\"])\n",
    "df_test = pd.merge(df_test, meta_data_merge_wide, how = \"left\", on = [\"subject_id\", \"hadm_id\"])\n",
    "df_train = df_train.drop(\"ICD9_diagnosis\", axis = 1)\n",
    "df_test = df_test.drop(\"ICD9_diagnosis\", axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning up vars to get age for each icu stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ADMITTIME'] = pd.to_datetime(df_train['ADMITTIME'])\n",
    "df_train['DOB'] = pd.to_datetime(df_train['DOB'])\n",
    "df_test['ADMITTIME'] = pd.to_datetime(df_test['ADMITTIME'])\n",
    "df_test['DOB'] = pd.to_datetime(df_test['DOB'])\n",
    "\n",
    "df_train['ADMITTIME'] += pd.to_timedelta(df_train['Diff'], unit = 'D')\n",
    "df_train['DOB'] += pd.to_timedelta(df_train['Diff'], unit = 'D')\n",
    "df_test['ADMITTIME'] += pd.to_timedelta(df_test['Diff'], unit = 'D')\n",
    "df_test['DOB'] += pd.to_timedelta(df_test['Diff'], unit = 'D')\n",
    "\n",
    "df_train.loc[df_train['DOB'].dt.year < 1900, 'DOB'] = np.nan\n",
    "df_test.loc[df_test['DOB'].dt.year < 1900, 'DOB'] = np.nan\n",
    "\n",
    "df_train['AGE'] = round((df_train['ADMITTIME'] - df_train['DOB']).dt.days / 365.25)\n",
    "df_test['AGE'] = round((df_test['ADMITTIME'] - df_test['DOB']).dt.days / 365.25)\n",
    "\n",
    "df_train.loc[df_train['AGE'].isna(), 'AGE'] = 93.0\n",
    "df_test.loc[df_train['AGE'].isna(), 'AGE'] = 93.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get more detailed information on the date of admission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train['ADMIT_HOUR'] = df_train['ADMITTIME'].dt.hour\n",
    "df_test['ADMIT_HOUR'] = df_test['ADMITTIME'].dt.hour\n",
    "\n",
    "df_train['ADMIT_MONTH'] = df_train['ADMITTIME'].dt.hour\n",
    "df_test['ADMIT_MONTH'] = df_test['ADMITTIME'].dt.hour\n",
    "\n",
    "df_train['ADMIT_YEAR'] = df_train['ADMITTIME'].dt.hour\n",
    "df_test['ADMIT_YEAR'] = df_test['ADMITTIME'].dt.hour\n",
    "\n",
    "# turn hour categorical by shift with 3 shifts (7-15, 15-23, 23-7)\n",
    "df_train['ADMIT_SHIFT'] = pd.cut(df_train['ADMIT_HOUR'], bins=[0, 7, 15, 23], labels=['night', 'morning', 'evening'])\n",
    "df_test['ADMIT_SHIFT'] = pd.cut(df_test['ADMIT_HOUR'], bins=[0, 7, 15, 23], labels=['night', 'morning', 'evening'])\n",
    "df_train['ADMIT_SHIFT'] = df_train['ADMIT_SHIFT'].astype(str)\n",
    "df_test['ADMIT_SHIFT'] = df_test['ADMIT_SHIFT'].astype(str)\n",
    "\n",
    "# turn month categorical by season\n",
    "df_train['ADMIT_SEASON'] = pd.cut(df_train['ADMIT_MONTH'], bins=[0, 3, 6, 9, 12], labels=['winter', 'spring', 'summer', 'fall'])\n",
    "df_test['ADMIT_SEASON'] = pd.cut(df_test['ADMIT_MONTH'], bins=[0, 3, 6, 9, 12], labels=['winter', 'spring', 'summer', 'fall'])\n",
    "df_train['ADMIT_SEASON'] = df_train['ADMIT_SEASON'].astype(str)\n",
    "df_test['ADMIT_SEASON'] = df_test['ADMIT_SEASON'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get number of icu stays for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train_count = df_train[['subject_id', 'ADMITTIME', 'icustay_id']].copy()\n",
    "df_test_count = df_test[['subject_id', 'ADMITTIME', 'icustay_id']].copy()\n",
    "\n",
    "df_train_count = df_train_count.sort_values(by = ['subject_id', 'ADMITTIME'])\n",
    "df_test_count = df_test_count.sort_values(by = ['subject_id', 'ADMITTIME'])\n",
    "\n",
    "df_train_count['previous_icu_stays'] = df_train_count.groupby('subject_id').cumcount()\n",
    "df_test_count['previous_icu_stays'] = df_test_count.groupby('subject_id').cumcount()\n",
    "\n",
    "df_train = pd.merge(df_train, df_train_count[['icustay_id', 'previous_icu_stays']], on = 'icustay_id', how = 'left')\n",
    "df_test = pd.merge(df_test, df_test_count[['icustay_id', 'previous_icu_stays']], on = 'icustay_id', how = 'left')\n",
    "\n",
    "\n",
    "df_train['prev_icu_visit'] = np.where(df_train['previous_icu_stays'] == 0, 0, 1)\n",
    "df_test['prev_icu_visit'] = np.where(df_test['previous_icu_stays'] == 0, 0, 1)\n",
    "\n",
    "df_train.drop('previous_icu_stays', axis = 1, inplace = True)\n",
    "df_test.drop('previous_icu_stays', axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin the age variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin age variable into 0–2, 3–5, 6–13, 14–18, 19–33, 34–48, 49–64, 65–78, and 79–98\n",
    "\n",
    "df_train['AGE_bin'] = pd.cut(df_train['AGE'], bins = [0, 2, 5, 13, 18, 33, 48, 64, 78, 98], labels = ['0-2', '3-5', '6-13', '14-18', '19-33', '34-48', '49-64', '65-78', '79-98'])\n",
    "df_test['AGE_bin'] = pd.cut(df_test['AGE'], bins = [0, 2, 5, 13, 18, 33, 48, 64, 78, 98], labels = ['0-2', '3-5', '6-13', '14-18', '19-33', '34-48', '49-64', '65-78', '79-98'])\n",
    "\n",
    "df_train['AGE_bin'] = df_train['AGE_bin'].astype(str)\n",
    "df_test['AGE_bin'] = df_test['AGE_bin'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the columns that are not useful anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['subject_id',\n",
    "                'hadm_id',\n",
    "                'icustay_id',\n",
    "                'DOD',\n",
    "                'DISCHTIME',\n",
    "                'DEATHTIME',\n",
    "                'Diff',\n",
    "                'ADMITTIME',\n",
    "                'DOB',\n",
    "                'ICD9_CODE_LIST',\n",
    "                'DIAGNOSIS',\n",
    "                'ICD9_diagnosis'\n",
    "                ]\n",
    "\n",
    "for col in cols_to_drop:\n",
    "    if col in df_train.columns:\n",
    "        df_train.drop(col, axis = 1, inplace = True)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if col in df_test.columns:\n",
    "        df_test.drop(col, axis = 1, inplace = True)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get columns by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HeartRate_Min', 'HeartRate_Max', 'HeartRate_Mean', 'SysBP_Min', 'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min', 'DiasBP_Max', 'DiasBP_Mean', 'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean', 'RespRate_Min', 'RespRate_Max', 'RespRate_Mean', 'TempC_Min', 'TempC_Max', 'TempC_Mean', 'SpO2_Min', 'SpO2_Max', 'SpO2_Mean', 'Glucose_Min', 'Glucose_Max', 'Glucose_Mean', 'UNIQUE_DIAGNOSIS_COUNT', 'DIAGNOSIS_COUNT', 'ICD9_mean', 'ICD9_max', 'ICD9_sum', 'AGE', 'ADMIT_HOUR', 'ADMIT_MONTH', 'ADMIT_YEAR', 'prev_icu_visit']\n",
      "['GENDER', 'ADMISSION_TYPE', 'INSURANCE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY', 'FIRST_CAREUNIT', 'code1', 'code2', 'code3', 'code4', 'code5', 'code6', 'code7', 'code8', 'code9', 'code10', 'code11', 'code12', 'code13', 'code14', 'code15', 'code16', 'code17', 'code18', 'code19', 'code20', 'code21', 'code22', 'code23', 'code24', 'code25', 'code26', 'code27', 'code28', 'code29', 'code30', 'code31', 'code32', 'code33', 'code34', 'code35', 'code36', 'code37', 'code38', 'code39', 'ADMIT_SHIFT', 'ADMIT_SEASON', 'AGE_bin']\n"
     ]
    }
   ],
   "source": [
    "def get_num_cat_cols():\n",
    "    n_cols = df_test.select_dtypes(include = ['number']).columns.tolist()\n",
    "    c_cols = df_test.select_dtypes(include = ['object']).columns.tolist()\n",
    "    \n",
    "    return n_cols, c_cols\n",
    "\n",
    "num_cols, cat_cols = get_num_cat_cols()\n",
    "\n",
    "print(num_cols)\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HeartRate_Min', 'HeartRate_Max', 'HeartRate_Mean', 'SysBP_Min', 'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min', 'DiasBP_Max', 'DiasBP_Mean', 'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean', 'RespRate_Min', 'RespRate_Max', 'RespRate_Mean', 'TempC_Min', 'TempC_Max', 'TempC_Mean', 'SpO2_Min', 'SpO2_Max', 'SpO2_Mean', 'Glucose_Min', 'Glucose_Max', 'Glucose_Mean', 'UNIQUE_DIAGNOSIS_COUNT', 'DIAGNOSIS_COUNT', 'ICD9_mean', 'ICD9_max', 'ICD9_sum', 'AGE', 'ADMIT_HOUR', 'ADMIT_MONTH', 'ADMIT_YEAR', 'prev_icu_visit']\n",
      "['GENDER', 'ADMISSION_TYPE', 'INSURANCE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY', 'FIRST_CAREUNIT', 'ADMIT_SHIFT', 'ADMIT_SEASON', 'AGE_bin']\n"
     ]
    }
   ],
   "source": [
    "num_cols, cat_cols = get_num_cat_cols()\n",
    "\n",
    "cat_cols = [c for c in cat_cols if c not in target_encoder_cols]\n",
    "\n",
    "print(num_cols)\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the preprocessing from the model solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ETHNICITY'] = df_train['ETHNICITY'].replace(['ASIAN', 'ASIAN - CHINESE', 'ASIAN - ASIAN INDIAN', 'ASIAN - VIETNAMESE', 'ASIAN - FILIPINO', 'ASIAN - CAMBODIAN',\n",
    "                                                     'ASIAN - JAPANESE', 'ASIAN - THAI', 'ASIAN - OTHER', 'ASIAN - KOREAN'\n",
    "                                                     ], 'ASIAN')\n",
    "\n",
    "df_train['ETHNICITY'] = df_train['ETHNICITY'].replace(['HISPANIC 0R LATINO', 'HISPANIC/LATINO - PUERTO RICAN', 'HISPANIC/LATINO - DOMINICAN',\n",
    "                                                     'HISPANIC/LATINO - GUATEMALAN', 'HISPANIC/LATINO - CUBAN', 'HISPANIC/LATINO - SALVADORAN',\n",
    "                                                     'HISPANIC/LATINO - MEXICAN', 'HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)', 'HISPANIC/LATINO - COLOMBIAN',\n",
    "                                                     'HISPANIC/LATINO - HONDURAN', 'SOUTH AMERICAN'\n",
    "                                                     ], 'HISPANIC OR LATINO')\n",
    "\n",
    "df_train['ETHNICITY'] = df_train['ETHNICITY'].replace(['WHITE', 'WHITE - RUSSIAN', 'WHITE - OTHER EUROPEAN', 'WHITE - EASTERN EUROPEAN',\n",
    "                                                     'WHITE - BRAZILIAN'\n",
    "                                                     ], 'WHITE')\n",
    "\n",
    "df_train['ETHNICITY'] = df_train['ETHNICITY'].replace(['BLACK/AFRICAN', 'BLACK/AFRICAN AMERICAN', 'BLACK/CAPE VERDEAN', 'BLACK/HAITIAN'\n",
    "                                                     ], 'BLACK')\n",
    "\n",
    "df_train['ETHNICITY'] = df_train['ETHNICITY'].replace(['UNABLE TO OBTAIN', 'UNKNOWN/NOT SPECIFIED', 'PATIENT DECLINED TO ANSWER'\n",
    "                                                     ], 'UNKNOWN')\n",
    "\n",
    "df_train['ETHNICITY'] = df_train['ETHNICITY'].replace(['AMERICAN INDIAN/ALASKA NATIVE', 'AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE',\n",
    "                                                     'CARIBBEAN ISLAND', 'MIDDLE EASTERN', 'OTHER', 'PORTUGUESE', 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER',\n",
    "                                                     'MULTI RACE ethnicity'\n",
    "                                                     ], 'OTHER')\n",
    "\n",
    "df_test['ETHNICITY'] = df_test['ETHNICITY'].replace(['ASIAN', 'ASIAN - CHINESE', 'ASIAN - ASIAN INDIAN', 'ASIAN - VIETNAMESE', 'ASIAN - FILIPINO', 'ASIAN - CAMBODIAN',\n",
    "                                                     'ASIAN - JAPANESE', 'ASIAN - THAI', 'ASIAN - OTHER', 'ASIAN - KOREAN'\n",
    "                                                     ], 'ASIAN')\n",
    "\n",
    "df_test['ETHNICITY'] = df_test['ETHNICITY'].replace(['HISPANIC 0R LATINO', 'HISPANIC/LATINO - PUERTO RICAN', 'HISPANIC/LATINO - DOMINICAN',\n",
    "                                                     'HISPANIC/LATINO - GUATEMALAN', 'HISPANIC/LATINO - CUBAN', 'HISPANIC/LATINO - SALVADORAN',\n",
    "                                                     'HISPANIC/LATINO - MEXICAN', 'HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)', 'HISPANIC/LATINO - COLOMBIAN',\n",
    "                                                     'HISPANIC/LATINO - HONDURAN', 'SOUTH AMERICAN'\n",
    "                                                     ], 'HISPANIC OR LATINO')\n",
    "\n",
    "df_test['ETHNICITY'] = df_test['ETHNICITY'].replace(['WHITE', 'WHITE - RUSSIAN', 'WHITE - OTHER EUROPEAN', 'WHITE - EASTERN EUROPEAN',\n",
    "                                                     'WHITE - BRAZILIAN'\n",
    "                                                     ], 'WHITE')\n",
    "\n",
    "df_test['ETHNICITY'] = df_test['ETHNICITY'].replace(['BLACK/AFRICAN', 'BLACK/AFRICAN AMERICAN', 'BLACK/CAPE VERDEAN', 'BLACK/HAITIAN'\n",
    "                                                     ], 'BLACK')\n",
    "\n",
    "df_test['ETHNICITY'] = df_test['ETHNICITY'].replace(['UNABLE TO OBTAIN', 'UNKNOWN/NOT SPECIFIED', 'PATIENT DECLINED TO ANSWER'\n",
    "                                                     ], 'UNKNOWN')\n",
    "\n",
    "df_test['ETHNICITY'] = df_test['ETHNICITY'].replace(['AMERICAN INDIAN/ALASKA NATIVE', 'AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE',\n",
    "                                                     'CARIBBEAN ISLAND', 'MIDDLE EASTERN', 'OTHER', 'PORTUGUESE', 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER',\n",
    "                                                     'MULTI RACE ethnicity'\n",
    "                                                     ], 'OTHER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion_other = ['HEBREW', 'UNITARIAN-UNIVERSALIST', 'HINDU', 'GREEK ORTHODOX',\"JEHOVAH'S WITNESS\", \"BUDDHIST\", 'MUSLIM', 'OTHER', 'CHRISTIAN SCIENTIST', 'EPISCOPALIAN', 'ROMANIAN EAST. ORTH', '7TH DAY ADVENTIST']\n",
    "df_train['RELIGION'] = df_train['RELIGION'].replace(religion_other, 'OTHER')\n",
    "df_test['RELIGION'] = df_test['RELIGION'].replace(religion_other, 'OTHER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train.loc[df_train['MARITAL_STATUS'].isna(), 'MARITAL_STATUS'] = 'UNKNOWN'\n",
    "df_train.loc[df_train['MARITAL_STATUS'] == 'UNKNOWN (DEFAULT)', 'MARITAL_STATUS'] = 'UNKNOWN'\n",
    "df_test.loc[df_test['MARITAL_STATUS'].isna(), 'MARITAL_STATUS'] = 'UNKNOWN'\n",
    "df_test.loc[df_test['MARITAL_STATUS'] == 'UNKNOWN (DEFAULT)', 'MARITAL_STATUS'] = 'UNKNOWN'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vital Sign Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we snake case the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = kl.clean_column_names(df_test)\n",
    "df_train = kl.clean_column_names(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate some vital sign features - we could potentially reduce dimensionality here, but will save the features for now. Most of these features came from chatGPT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_engineering(df):\n",
    "    df['shock_index'] = df['heart_rate_mean'] / df['sys_bp_mean']\n",
    "    df['mean_arterial_pressure'] = df['dias_bp_mean'] + (df['sys_bp_mean'] - df['dias_bp_mean']) / df.shape[0]\n",
    "    df['temp_variability'] = df['temp_c_max'] - df['temp_c_min']\n",
    "    df['oxygen_saturation_variability'] = df['sp_o2_max'] - df['sp_o2_min']\n",
    "    df['glucose_variability'] = df['glucose_max'] - df['glucose_min']\n",
    "    df['cardiovasular_risk'] = df[['heart_rate_mean', 'sys_bp_mean', 'dias_bp_mean', 'mean_bp_mean']].mean(axis=1)\n",
    "    df['pulse_pressure'] = df['sys_bp_mean'] - df['dias_bp_mean']\n",
    "    df['oxygenation_index'] = df['resp_rate_mean'] / df['sp_o2_mean'] \n",
    "    df['thermal_stress_index'] = df['temp_c_mean'] * df['heart_rate_mean']\n",
    "    df['fever_indicator'] = df['temp_c_mean'] > 37.5\n",
    "    df['fever_indicator'] = df['fever_indicator'].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = feature_engineering(df_train)\n",
    "df_test = feature_engineering(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data\n",
    "Later we could potentially use this in a BERT model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we map the text data to each 'code' column using a dictionary defined at the beginning of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hospital_expire_flag', 'heart_rate_min', 'heart_rate_max',\n",
       "       'heart_rate_mean', 'sys_bp_min', 'sys_bp_max', 'sys_bp_mean',\n",
       "       'dias_bp_min', 'dias_bp_max', 'dias_bp_mean',\n",
       "       ...\n",
       "       'code35_short_text', 'code35_long_text', 'code36_short_text',\n",
       "       'code36_long_text', 'code37_short_text', 'code37_long_text',\n",
       "       'code38_short_text', 'code38_long_text', 'code39_short_text',\n",
       "       'code39_long_text'],\n",
       "      dtype='object', length=173)"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_cols = [col for col in df_train.columns if 'code' in col]\n",
    "\n",
    "df_train[code_cols] = df_train[code_cols].fillna('')\n",
    "df_test[code_cols] = df_test[code_cols].fillna('')\n",
    "\n",
    "short_cols = []\n",
    "long_cols = []\n",
    "short_diagnose_dict[''] = ''\n",
    "long_diagnose_dict[''] = ''\n",
    "\n",
    "for col in code_cols:\n",
    "    short_col = col + '_short_text'\n",
    "    df_train[short_col] = df_train[col].astype(str).map(short_diagnose_dict)\n",
    "    df_test[short_col] = df_test[col].astype(str).map(short_diagnose_dict)\n",
    "    short_cols.append(short_col)\n",
    "\n",
    "    long_col = col + '_long_text'\n",
    "    df_train[long_col] = df_train[col].astype(str).map(long_diagnose_dict)\n",
    "    df_test[long_col] = df_test[col].astype(str).map(long_diagnose_dict)\n",
    "    long_cols.append(long_col)\n",
    "\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a concatenated text field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = long_cols + short_cols\n",
    "df_train['all_text'] = df_train[all_cols].apply(lambda row: ' '.join(row.values.astype(str)), axis = 1)\n",
    "df_test['all_text'] = df_test[all_cols].apply(lambda row: ' '.join(row.values.astype(str)), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we drop all of the text and code columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(columns = all_cols, axis = 1, inplace = True)\n",
    "df_train.drop(columns = all_cols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get numerical columns for imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heart_rate_min', 'heart_rate_max', 'heart_rate_mean', 'sys_bp_min', 'sys_bp_max', 'sys_bp_mean', 'dias_bp_min', 'dias_bp_max', 'dias_bp_mean', 'mean_bp_min', 'mean_bp_max', 'mean_bp_mean', 'resp_rate_min', 'resp_rate_max', 'resp_rate_mean', 'temp_c_min', 'temp_c_max', 'temp_c_mean', 'sp_o2_min', 'sp_o2_max', 'sp_o2_mean', 'glucose_min', 'glucose_max', 'glucose_mean', 'unique_diagnosis_count', 'diagnosis_count', 'icd9_mean', 'icd9_max', 'icd9_sum', 'age', 'admit_hour', 'admit_month', 'admit_year', 'prev_icu_visit', 'shock_index', 'mean_arterial_pressure', 'temp_variability', 'oxygen_saturation_variability', 'glucose_variability', 'cardiovasular_risk', 'pulse_pressure', 'oxygenation_index', 'thermal_stress_index', 'fever_indicator']\n",
      "['gender', 'admission_type', 'insurance', 'religion', 'marital_status', 'ethnicity', 'first_careunit', 'code1', 'code2', 'code3', 'code4', 'code5', 'code6', 'code7', 'code8', 'code9', 'code10', 'code11', 'code12', 'code13', 'code14', 'code15', 'code16', 'code17', 'code18', 'code19', 'code20', 'code21', 'code22', 'code23', 'code24', 'code25', 'code26', 'code27', 'code28', 'code29', 'code30', 'code31', 'code32', 'code33', 'code34', 'code35', 'code36', 'code37', 'code38', 'code39', 'admit_shift', 'admit_season', 'age_bin']\n"
     ]
    }
   ],
   "source": [
    "# get all numerical columns\n",
    "num_cols, cat_cols = get_num_cat_cols()\n",
    "cat_cols = [col for col in cat_cols if col not in ['all_text']]\n",
    "print(num_cols)\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard KNN imputer. I found 10 neighbors worked well in a previous notebook on a different similar dimension sized dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import knn imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "\n",
    "df_train_imputed = imputer.fit_transform(df_train[num_cols])\n",
    "\n",
    "df_train_imputed = pd.DataFrame(df_train_imputed, columns = num_cols, index = df_train.index)\n",
    "\n",
    "df_test_imputed = imputer.transform(df_test[num_cols])\n",
    "\n",
    "df_test_imputed = pd.DataFrame(df_test_imputed, columns = num_cols, index = df_test.index)\n",
    "\n",
    "df_train[num_cols] = df_train_imputed\n",
    "\n",
    "df_test[num_cols] = df_test_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare columns for encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encode_cols = ['gender','marital_status', 'ethnicity', 'age_bin']\n",
    "binary_encode_cols = ['religion']\n",
    "target_encode_cols = [col for col in cat_cols if col not in one_hot_encode_cols and not col in binary_encode_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary encode columns\n",
    "\n",
    "Binary encoding is a good choice for columns with low cardinality. Compared to one hot encoding, it reduces the number of columns created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_encoder = ce.BinaryEncoder(cols = binary_encode_cols, return_df = True)\n",
    "\n",
    "df_train_binary = df_train[binary_encode_cols].copy()\n",
    "df_test_binary = df_test[binary_encode_cols].copy()\n",
    "\n",
    "binary_tr = binary_encoder.fit(df_train[binary_encode_cols])\n",
    "\n",
    "df_train_binary_encd = binary_tr.transform(df_train_binary)\n",
    "df_test_binary_encd = binary_tr.transform(df_test_binary)\n",
    "\n",
    "df_train = pd.concat([df_train.drop(columns = binary_encode_cols, axis = 1,), df_train_binary_encd], axis = 1)\n",
    "df_test = pd.concat([df_test.drop(columns = binary_encode_cols, axis = 1,), df_test_binary_encd], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target encode columns\n",
    "\n",
    "Target encoding encodes the column based on the target metric, in this case LOS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target encode cat_cols \n",
    "target_encoder = ce.TargetEncoder(cols = target_encode_cols, return_df = True)\n",
    "\n",
    "df_train_target = df_train[target_encode_cols].copy()\n",
    "df_test_target = df_test[target_encode_cols].copy()\n",
    "\n",
    "target_tr = target_encoder.fit(df_train_target, df_train['los'])\n",
    "\n",
    "df_train_target_encd = target_tr.transform(df_train_target)\n",
    "df_test_target_encd = target_tr.transform(df_test_target)\n",
    "\n",
    "df_train = pd.concat([df_train.drop(columns = target_encode_cols, axis = 1,), df_train_target_encd], axis = 1)\n",
    "df_test = pd.concat([df_test.drop(columns = target_encode_cols, axis = 1,), df_test_target_encd], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encode columns\n",
    "\n",
    "One hot encoding creates binary columns for each category type. Compared to binary encoding, it is better for columns with high cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20885, 98)\n",
      "(20885, 116)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "\n",
    "# one hot encode cat_cols\n",
    "one_hot_encoder = ce.OneHotEncoder(cols = one_hot_encode_cols, return_df = True)\n",
    "\n",
    "df_train_one_hot = df_train[one_hot_encode_cols].copy()\n",
    "df_test_one_hot = df_test[one_hot_encode_cols].copy()\n",
    "\n",
    "one_hot_tr = one_hot_encoder.fit(df_train_one_hot)\n",
    "\n",
    "df_train_one_hot_encd = one_hot_tr.transform(df_train_one_hot)\n",
    "df_test_one_hot_encd = one_hot_tr.transform(df_test_one_hot)\n",
    "\n",
    "df_train = pd.concat([df_train.drop(columns = one_hot_encode_cols, axis = 1,), df_train_one_hot_encd], axis = 1)\n",
    "df_test = pd.concat([df_test.drop(columns = one_hot_encode_cols, axis = 1,), df_test_one_hot_encd], axis = 1)\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First getting columns by skewness to determine which to robust scale and which to log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols, cat_cols = get_num_cat_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = ['hospital_expire_flag'], axis = 1)\n",
    "\n",
    "# get columns with skew greater than 0.5\n",
    "skew_cols = df_train[num_cols].apply(lambda x: x.skew()).sort_values(ascending = False)\n",
    "skew_cols = skew_cols[skew_cols > 0.5].index.tolist()\n",
    "\n",
    "# get columns with 0,1 only\n",
    "binary_cols = df_train[cat_cols].apply(lambda x: x.nunique()).sort_values()\n",
    "binary_cols = binary_cols[binary_cols == 2].index.tolist()\n",
    "\n",
    "# get columns not in binary and skew columns\n",
    "other_cols = [col for col in df_train.columns if col not in binary_cols]\n",
    "other_cols = [col for col in other_cols if col not in skew_cols]\n",
    "other_cols.remove('los')\n",
    "other_cols.remove('all_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log transform columns\n",
    "\n",
    "As we saw in class, we can first log scale then use a regular scaler. So here we log transform the columns with skewness > 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols_to_log = [col for col in num_cols if abs(df_train[col].skew()) > 1]\n",
    "\n",
    "#log transform skewed columns\n",
    "for col in cols_to_log:\n",
    "    df_train[col] = np.log1p(df_train[col])\n",
    "    df_test[col] = np.log1p(df_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robust Scale Columns\n",
    "\n",
    "We found columns with skew > .5 so we will robust scale those columns. Robust scaling scales the data based on the median and IQR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust scale skew_cols\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "df_train_robust = df_train[skew_cols].copy()\n",
    "df_test_robust = df_test[skew_cols].copy()\n",
    "\n",
    "robust_tr = robust_scaler.fit(df_train_robust)\n",
    "\n",
    "df_train_robust_scaled = robust_tr.transform(df_train_robust)\n",
    "df_test_robust_scaled = robust_tr.transform(df_test_robust)\n",
    "\n",
    "df_train_robust_scaled = pd.DataFrame(df_train_robust_scaled, columns = df_train_robust.columns, index = df_train_robust.index)\n",
    "df_test_robust_scaled = pd.DataFrame(df_test_robust_scaled, columns = df_test_robust.columns, index = df_test_robust.index)\n",
    "\n",
    "df_train = pd.concat([df_train.drop(columns = skew_cols, axis = 1,), df_train_robust_scaled], axis = 1)\n",
    "df_test = pd.concat([df_test.drop(columns = skew_cols, axis = 1,), df_test_robust_scaled], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scale Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found columns with skew < .5 so we will standard scale those columns. Standard scaling scales the data based on the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# standard scale non_skew_cols and dummy_cols\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "df_train_standard = df_train[list(set(other_cols + binary_cols))].copy()\n",
    "df_test_standard = df_test[list(set(other_cols + binary_cols))].copy()\n",
    "\n",
    "standard_tr = standard_scaler.fit(df_train_standard)\n",
    "\n",
    "df_train_standard_scaled = standard_tr.transform(df_train_standard)\n",
    "df_test_standard_scaled = standard_tr.transform(df_test_standard)\n",
    "\n",
    "df_train_standard_scaled = pd.DataFrame(df_train_standard_scaled, columns = df_train_standard.columns, index = df_train_standard.index)\n",
    "df_test_standard_scaled = pd.DataFrame(df_test_standard_scaled, columns = df_test_standard.columns, index = df_test_standard.index)\n",
    "\n",
    "df_train = pd.concat([df_train.drop(columns = list(set(other_cols + binary_cols)), axis = 1,), df_train_standard_scaled], axis = 1)\n",
    "df_test = pd.concat([df_test.drop(columns = list(set(other_cols + binary_cols)), axis = 1,), df_test_standard_scaled], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the data to a csv file for use in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df_train.to_csv('data/train_cleaned_2.csv', index = False)\n",
    "df_test.to_csv('data/test_cleaned_2.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
